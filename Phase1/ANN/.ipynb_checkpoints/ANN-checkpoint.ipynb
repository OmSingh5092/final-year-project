{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3201c8-a735-4497-b59e-1e01831da8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad861d9a-1472-4503-9d90-c9fe14cf93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from csv file\n",
    "\n",
    "dataset = pd.read_csv('../../DataSets/data_set_dra_updated.csv')\n",
    "\n",
    "x = pd.DataFrame(dataset.iloc[:, 0:6].values)\n",
    "y = dataset.iloc[:, 6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02eaa61f-a48c-46dd-9251-a93041462cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training and test data sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eecc7b2c-fa09-4b2f-a089-8166d1f100e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial NN\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "classifier.add(Dense(units = 10, activation = 'relu', input_dim = 6))\n",
    "\n",
    "# 1st Hidden Layer\n",
    "classifier.add(Dense(units = 8, activation = 'relu'))\n",
    "\n",
    "# 2nd Hidden Layer\n",
    "classifier.add(Dense(units = 3, activation = 'relu'))\n",
    "\n",
    "# Output Layer\n",
    "classifier.add(Dense(units = 1, activation = 'linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2137ba00-034d-497b-9ffb-28e69e94f666",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m      3\u001b[0m classifier\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "history=classifier.fit(x_train, y_train, batch_size = 10, epochs = 100, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f1d1f-6d17-45c9-9ddb-76a2318922e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8961f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Metrics\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "MSE = mse(y_test, y_pred)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "MAX_ERROR = max_error(y_test, y_pred);\n",
    "MEAN_ABSOLUTE_ERROR = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error\", MSE)\n",
    "print(\"R-Squared: \", R2)\n",
    "print(\"Max Error\", MAX_ERROR);\n",
    "print(\"Mean Absolute Error\", MEAN_ABSOLUTE_ERROR);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30825f7-27a1-4ef4-a3b7-4115a94d5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Analysis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('LOSS')\n",
    "plt.xlabel('EPOCH')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Validation Loss')\n",
    "plt.ylabel('VAL LOSS')\n",
    "plt.xlabel('EPOCH')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff72629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Plot\n",
    "\n",
    "def generatePredictionPlot(y_pred, y_test):\n",
    "    plt.scatter(x=y_test, y=y_pred, c='navy', alpha=0.6)\n",
    "    plt.plot(y_test, y_test,color='cyan')\n",
    "    plt.title('Predicted vs Actual values')\n",
    "    plt.xlabel('Actual values')\n",
    "    plt.ylabel('Predicted values')\n",
    "    plt.show()\n",
    "    \n",
    "generatePredictionPlot(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Samples\n",
    "\n",
    "d1 = [14.10, 14.55, 2.25, 2.6, 2.42] #HFSS S11 = -0.37\n",
    "d2 = [13.04, 13.30, 2.3, 2.7, 1.84] # HFSS S11 = -0.43\n",
    "d3 = [13.19, 13.74, 2.7, 2.45, 1.95] # HFSS S11 = -0.44\n",
    "d4 = [14.42, 13.12, 2.4, 2.8, 2.41] # HFSS S11 = -0.51\n",
    "d5 = [13.86, 14.57, 2.8, 2.1, 2.56] #HFSS S11 = -0.77\n",
    "\n",
    "# Predictions\n",
    "preds = classifier.predict([d1,d2,d3,d4,d5])\n",
    "\n",
    "print(\"Predictions\", preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6da811-8565-4477-a568-dec96c8e608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random data sets\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "SAMPLE_SIZE = 10\n",
    "\n",
    "def randomSample(low, high, size):\n",
    "    rand_rad = numpy.random.uniform(low, high, size)\n",
    "    for i in range(0, rand_rad.size):\n",
    "        rand_rad[i] = round(rand_rad[i], 2)\n",
    "    return rand_rad\n",
    "\n",
    "rand_rad = randomSample(12, 14, SAMPLE_SIZE)\n",
    "rand_height = randomSample(13, 14, SAMPLE_SIZE)\n",
    "rand_freq = randomSample(2, 6, SAMPLE_SIZE)\n",
    "rand_w1 = randomSample(2.5, 3.5, SAMPLE_SIZE)\n",
    "rand_w2 = randomSample(2.5, 3.5, SAMPLE_SIZE)\n",
    "\n",
    "rand_x = []\n",
    "for i in range(0,SAMPLE_SIZE):\n",
    "    rand_x.append([rand_height[i], rand_rad[i], rand_w1[i], rand_w2[i], rand_freq[i],])\n",
    "\n",
    "y_pred_rand = classifier.predict(rand_x)\n",
    "\n",
    "output = []\n",
    "for i in range(0, SAMPLE_SIZE):\n",
    "    output.append([rand_height[i], rand_rad[i], rand_w1[i], rand_w2[i], rand_freq[i], y_pred_rand[i]])\n",
    "    \n",
    "# Creating Dataframe\n",
    "output_df = pandas.DataFrame(output, columns= [\"Height\", \"Radius\", \"W1\", \"W2\", \"Frequency\", \"S11\"])\n",
    "print(\"Predicted Values for random samples\\n\")\n",
    "print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5714996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aabbff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
